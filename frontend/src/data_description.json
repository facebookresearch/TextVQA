{
    "textvqa": {
        "data": [
            {
                "question_id": "INT, incremental unique ID for the question",
                "question": "what is ....?",
                "question_tokens": ["token_1", "token_2", "...", "token_N"],
                "image_id": "OpenImages Image ID",
                "image_classes": ["OpenImages_class_1", "OpenImages_class_2", "...",
                    "OpenImages_class_n"],
                "flickr_original_url": "OpenImages original flickr url",
                "flickr_300k_url": "OpenImages flickr 300k thumbnail url",
                "image_width": "INT, Width of the image",
                "image_height": "INT, Height of the image",
                "set_name": "Dataset split question belongs to",
                "answers": [
                    "answer_1",
                    "answer_2",
                    "...",
                    "answer_10"
                ]
            }
        ],
        "dataset_type": "Split train|val|test",
        "dataset_name": "textvqa",
        "dataset_version": "VERSION"
    },
    "textcaps": {
        "data": [
            {
                "image_id": "Alphanumeric String, unique OpenImages Image ID",
                "caption_str": "The poster says ...",
                "caption_tokens": ["token_1", "token_2", "...", "token_N"],
                "caption_id": "INT, incremental unique caption ID",
                "image_classes": ["OpenImages_class_1", "OpenImages_class_2", "...",
                    "OpenImages_class_n"],
                "flickr_original_url": "OpenImages original flickr url",
                "flickr_300k_url": "OpenImages flickr 300k thumbnail url",
                "image_width": "INT, Width of the image",
                "image_height": "INT, Height of the image",
                "set_name": "Dataset split question belongs to",
                "reference_strs": [
                    "caption_1",
                    "...",
                    "...",
                    "caption_5"
                ],
                "reference_tokens": [
                    ["token_1_1", "...", "token_1_n"],
                    ["..."],
                    ["token_5_1", "...", "token_5_n"]
                ]
            }
        ],
        "dataset_type": "Split train|val|test",
        "dataset_name": "textcaps",
        "dataset_version": "VERSION"
    },
    "ocr": {
        "data": {
            "image_id": "STRING",
            "ocr_tokens": [
                "OCR extracted text 1",
                "OCR extracted text 2",
                "...",
                "OCR extracted text N"
            ],
            "ocr_info": [
                {
                    "bounding_box": {
                        "top_left_x": "FLOAT, top left x coordinate of the OCR box",
                        "top_left_y": "FLOAT, top left y coordinate of the OCR box",
                        "width": "FLOAT (between 0 to 1), relative width of the OCR box",
                        "height": "FLOAT (between 0 to 1), relative height of the OCR box",
                        "rotation": "Rotation angle of the extracted text",
                        "yaw": "Yaw of the extracted text",
                        "roll": "Roll of the extracted text",
                        "pitch": "Pitch of the extracted text"
                    },
                    "word": "Extracted word unformatted"
                }
            ]
        },
        "dataset_type": "Split train|val|test",
        "dataset_name": "textvqa_ocr",
        "dataset_version": "VERSION"
    },
    "textocr": {
        "imgs": {
            "OpenImages_ImageID_1": {
                "id": "OpenImages_ImageID_1",
                "width": "INT, Width of the image",
                "height": "INT, Height of the image",
                "set": "Split train|val|test",
                "filename": "train|test/OpenImages_ImageID_1.jpg"
            },
            "OpenImages_ImageID_2": {"...": "..."}
        },
        "anns": {
            "OpenImages_ImageID_1_1": {
                "id": "STR, OpenImages_ImageID_1_1, Specifies the nth annotation for an image",
                "image_id": "OpenImages_ImageID_1",
                "bbox": ["FLOAT x1", "FLOAT y1", "FLOAT x2", "FLOAT y2"],
                "points": [
                        "FLOAT x1",
                        "FLOAT y1",
                        "FLOAT x2",
                        "FLOAT y2",
                        "...",
                        "FLOAT xN",
                        "FLOAT yN"
                ],
                "utf8_string": "text for this annotation",
                "area": "FLOAT, area of this box"
            },
            "OpenImages_ImageID_1_2": {"...": "..."},
            "OpenImages_ImageID_2_1": {"...": "..."}
        },
        "img2Anns": {
            "OpenImages_ImageID_1": [
                "OpenImages_ImageID_1_1",
                "OpenImages_ImageID_1_2",
                "OpenImages_ImageID_1_2"
            ],
            "OpenImages_ImageID_N": ["..."]
        }
    }
}